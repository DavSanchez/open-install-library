# Visit our schema definition for additional information on this file format
# https://github.com/newrelic/open-install-library/blob/main/docs/recipe-spec/recipe-spec.md#schema-definition

name: pihole-installer
displayName: Raspberry Pi PiHole Integration
description: New Relic install recipe for pihole on Raspberry Pi
repository: https://github.com/newrelic/nri-prometheus

stability: experimental

installTargets:
  - type: host
    os: linux
    platformFamily: debian
    kernelArch: ARMV7L

keywords:
  - raspberrypi
  - infrastructure

processMatch: []

validationNrql: "FROM Metric SELECT count(*) where metricName like 'pihole_%' facet piHoleName since 10 minutes ago"

inputVars:
  - name: "NR_PROMETHEUS_DATA_SOURCE"
    prompt: "Data Source Identifier"
    default: "pi-prometheus"

preInstall:
  info: |2
      Note: EXPERIMENTAL RECIPE
      This installation installs Prometheus and PiHole Exporter as background services. Additionally,
      a container named 'nri-prometheus' will be run in the background to facilitate metrics collection.

install:
  version: "3"
  silent: true

  tasks:
    default:
      cmds:
        - task: assert_pre_req
        - task: teardown_existing
        - task: install_prometheus
        - task: install_pihole_exporter
        - task: install_nri_prometheus
        - task: cleanup
        # - task: restart
        # - task: assert_agent_started

    assert_pre_req:
      cmds:
        - |
          IS_GREP_INSTALLED=$(which grep | wc -l)
          if [ $IS_GREP_INSTALLED -eq 0 ] ; then
            echo "grep is required to run the newrelic install. Please install grep and re-run the installation." >> /dev/stderr
            exit 10
          fi
        - |
          IS_WGET_INSTALLED=$(which wget | wc -l)
          if [ $IS_WGET_INSTALLED -eq 0 ] ; then
            echo "wget is required to run the newrelic install. Please install wget and re-run the installation." >> /dev/stderr
            exit 11
          fi
        - |
          IS_TAR_INSTALLED=$(which tar | wc -l)
          if [ $IS_TAR_INSTALLED -eq 0 ] ; then
            echo "tar is required to run the newrelic install. Please install tar and re-run the installation." >> /dev/stderr
            exit 12
          fi
        - |
          IS_CAT_INSTALLED=$(which cat | wc -l)
          if [ $IS_CAT_INSTALLED -eq 0 ] ; then
            echo "cat is required to run the newrelic install. Please install cat and re-run the installation." >> /dev/stderr
            exit 13
          fi
        - |
          IS_TEE_INSTALLED=$(which tee | wc -l)
          if [ $IS_TEE_INSTALLED -eq 0 ] ; then
            echo "tee is required to run the newrelic install. Please install tee and re-run the installation." >> /dev/stderr
            exit 14
          fi
        - |
          IS_TOUCH_INSTALLED=$(which touch | wc -l)
          if [ $IS_TOUCH_INSTALLED -eq 0 ] ; then
            echo "touch is required to run the newrelic install. Please install touch and re-run the installation." >> /dev/stderr
            exit 15
          fi
        - |
          IS_DOCKER_CONTAINER=$(sudo grep 'docker\|lxc' /proc/1/cgroup | wc -l)
          if [ $IS_DOCKER_CONTAINER -gt 0 ] ; then
            echo "We’ve detected that you are installing our infrastructure agent inside a docker container. This agent is not designed to be installed within a container, but rather on the host it is running on or as a separate container. For additional information visit: https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/" >> /dev/stderr
            exit 18
          fi
        - |
          IS_WSL_CONTAINER=$(sudo grep -i 'Microsoft' /proc/version | wc -l)
          if [ $IS_WSL_CONTAINER -gt 0 ] ; then
            echo "Sorry, our infrastructure agent cannot be installed for Microsoft Windows Subsystem for Linux, this is an unsupported operating system." >> /dev/stderr
            exit 19
          fi

    teardown_existing:
      cmds:
        - |
          if [ {{.IS_SYSTEMCTL}} -gt 0 ]; then
            sudo systemctl stop prometheus
            sudo systemctl stop pihole_exporter
          else
            if [ {{.IS_INITCTL}} -gt 0 ]; then
              sudo initctl stop prometheus
              sudo initctl stop pihole_exporter              
            else
              sudo /etc/init.d/prometheus stop
              sudo /etc/init.d/pihole_exporter stop
            fi
          fi
        - |
          mkdir -p /tmp/newrelic
          sudo rm -rf /tmp/newrelic/* 

          if [ -f /opt/prometheus/prometheus.yml ]; then
            mv -f /opt/prometheus/prometheus.yml /tmp/newrelic/prometheus_old.yml
            rm -f /opt/prometheus/prometheus.yml
          fi

          sudo rm -rf /opt/prometheus/*
          sudo rm -rf /opt/pihole_exporter/*
        # - |
        #   sudo tee /etc/newrelic-infra.yml > /dev/null <<"EOT"
        #   license_key: {{.NEW_RELIC_LICENSE_KEY}}
        #   enable_process_metrics: true
        #   EOT
        # - |
        #   if [ $(echo {{.NEW_RELIC_REGION}} | grep -i staging | wc -l) -gt 0 ]; then
        #     echo 'staging: true' | sudo tee -a /etc/newrelic-infra.yml > /dev/null
        #   fi
      vars:
        IS_SYSTEMCTL:
          sh: which systemctl | wc -l
        IS_INITCTL:
          sh: which initctl | wc -l

    install_prometheus:
      cmds:
        - |
          ####################################################################################################################################################
          # Cleanup
          ####################################################################################################################################################
          # mkdir -p /tmp/newrelic

          # if [ -f /opt/prometheus/prometheus.yml ]; then
          #   mv -f /opt/prometheus/prometheus.yml /tmp/newrelic/prometheus_old.yml
          #   rm -f /opt/prometheus/prometheus.yml
          # fi

          # sudo rm -rf /tmp/newrelic/* /opt/prometheus/*
          cd /tmp/newrelic


          ####################################################################################################################################################
          # Download Prometheus
          ####################################################################################################################################################
          curl -s https://api.github.com/repos/prometheus/prometheus/releases/latest \
          | grep "browser_download_url.*prometheus-*.*.linux-armv7.tar.gz" \
          | cut -d '"' -f 4 \
          | wget -i -
          tar xvfz prometheus-*.*.linux-armv7.tar.gz

          ####################################################################################################################################################
          # Move to /opt
          ####################################################################################################################################################
          mkdir -p /opt/prometheus
          mv prometheus-*.*.linux-armv7/* /opt/prometheus
          rm prometheus-*.*.linux-armv7.tar.gz

          ####################################################################################################################################################  
          # Write prometheus config
          ####################################################################################################################################################
          sudo tee /opt/prometheus/prometheus.yml > /dev/null <<"EOT"
          # my global config
          global:
            scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
            evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
            # scrape_timeout is set to the global default (10s).
          # remote_write: 
          # - url: https://staging-metric-api.newrelic.com/prometheus/v1/write?X-License-Key={{.NEW_RELIC_LICENSE_KEY}}&prometheus_server={{.NR_PROMETHEUS_DATA_SOURCE}}

          # Alertmanager configuration
          alerting:
            alertmanagers:
            - static_configs:
              - targets:
                # - alertmanager:9093

          # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
          rule_files:
            # - "first_rules.yml"
            # - "second_rules.yml"

          # A scrape configuration containing exactly one endpoint to scrape:
          # Here it's Prometheus itself.
          scrape_configs:
            # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
            - job_name: 'prometheus'

              # metrics_path defaults to '/metrics'
              # scheme defaults to 'http'.

              static_configs:
              - targets: ['localhost:9090']
            # - job_name: 'pihole'
            #   static_configs:
            #     - targets: ['localhost:9617']
          EOT

          ####################################################################################################################################################
          # Run Prometheus as a service
          ####################################################################################################################################################
          sudo tee /etc/systemd/system/prometheus.service > /dev/null <<"EOT" 
          [Unit]
          Description=Prometheus Server
          Documentation=https://prometheus.io/docs/introduction/overview/
          After=network-online.target

          [Service]
          User=root
          Restart=always

          ExecStart=/opt/prometheus/prometheus \
            --config.file=/opt/prometheus/prometheus.yml \
            --storage.tsdb.path=/opt/prometheus/data

          [Install]
          WantedBy=multi-user.target
          EOT

          ####################################################################################################################################################
          # Enable and start
          ####################################################################################################################################################
          sudo systemctl daemon-reload
          sudo systemctl enable prometheus
          sudo systemctl start prometheus

          ####################################################################################################################################################
          # Cleanup
          ####################################################################################################################################################
          if [ -f /tmp/newrelic/prometheus_old.yml ]; then
            mv /tmp/newrelic/prometheus_old.yml /opt/prometheus/
          fi

          # wget https://download.newrelic.com/infrastructure_agent/binaries/linux/arm/newrelic-infra_linux_1.16.5_arm.tar.gz
          # tar xvfz newrelic-infra_linux_1.16.5_arm.tar.gz
          # cd newrelic-infra
          # sudo NRIA_LICENSE_KEY={{.NEW_RELIC_LICENSE_KEY}} ./installer.sh
          # echo "enable_process_metrics: true" | sudo tee -a /etc/newrelic-infra.yml
      silent: true

    install_pihole_exporter:
      - |
        ####################################################################################################################################################
        # Cleanup
        ####################################################################################################################################################
        # mkdir -p /tmp/newrelic
        # sudo rm -rf /tmp/newrelic/* /opt/pihole_exporter/*
        cd /tmp/newrelic

        ####################################################################################################################################################
        # Download the latest pihole-exporter https://github.com/eko/pihole-exporter/releases/latest/download/pihole_exporter-linux-arm
        ####################################################################################################################################################
        curl -s https://api.github.com/repos/eko/pihole-exporter/releases/latest \
        | grep "browser_download_url.*pihole_exporter-linux-arm" \
        | cut -d '"' -f 4 \
        | wget -i -

        ####################################################################################################################################################
        # Move to /opt
        ####################################################################################################################################################
        mkdir -p /opt/pihole_exporter
        mv pihole_exporter-linux-arm /opt/pihole_exporter

        # # Set permissions
        # chgrp root /opt/pihole_exporter
        # chgrp root /opt/pihole_exporter/pihole_exporter-linux-arm
        chmod +x /opt/pihole_exporter/pihole_exporter-linux-arm

        ####################################################################################################################################################
        # Run pihole-exporter as a service
        ####################################################################################################################################################
        sudo tee /etc/systemd/system/pihole_exporter.service > /dev/null <<"EOT" 
        [Unit]
        Description=pihole_exporter
        After=network-online.target

        [Service]
        ExecStart=/opt/pihole_exporter/pihole_exporter-linux-arm
        WorkingDirectory=/opt/pihole_exporter
        Restart=always
        User=root

        [Install]
        WantedBy=multi-user.target
        EOT

        ####################################################################################################################################################
        # Enable and start
        ####################################################################################################################################################
        sudo systemctl daemon-reload
        sudo systemctl enable pihole_exporter
        sudo systemctl start pihole_exporter

    install_nri_prometheus:
      - |
        ####################################################################################################################################################
        # Cleanup
        ####################################################################################################################################################
        mkdir -p /etc/nri-prometheus
        if [ -f /etc/nri-prometheus/nri-prometheus-config.yml ]; then
          mv /etc/nri-prometheus/nri-prometheus-config.yml /tmp/newrelic/nri-prometheus-config_old.yml
        fi
        docker stop nri-prometheus || true

        HOST_IP=$(hostname -I | awk '{print $1;}')
        sudo tee /etc/nri-prometheus/nri-prometheus-config.yml > /dev/null <<EOT
        # The name of your cluster. It's important to match other New Relic products to relate the data.
        cluster_name: "{{.NR_PROMETHEUS_DATA_SOURCE}}"
        # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true
        # standalone: true

        # How often the integration should run. Defaults to 30s.
        scrape_duration: "10s"
        # The HTTP client timeout when fetching data from endpoints. Defaults to 5s.
        scrape_timeout: "5s"

        # How old must the entries used for calculating the counters delta be
        # before the telemetry emitter expires them. Defaults to 5m.
        # telemetry_emitter_delta_expiration_age: "5m"

        # How often must the telemetry emitter check for expired delta entries.
        # Defaults to 5m.
        # telemetry_emitter_delta_expiration_check_interval: "5m"

        # Wether the integration should run in verbose mode or not. Defaults to false.
        # verbose: false

        # Whether the integration should run in audit mode or not. Defaults to false.
        # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent.
        # It does not include verbose mode. This can lead to a high log volume, use with care.
        # audit: false

        # Wether the integration should skip TLS verification or not. Defaults to false.
        # insecure_skip_verify: false

        # The label used to identify scrapable targets. Defaults to "prometheus.io/scrape".
        # scrape_enabled_label: "prometheus.io/scrape"

        # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true.
        # require_scrape_enabled_label_for_nodes: true

        # Number of worker threads used for scraping targets.
        # For large clusters with many (>400) endpoints, slowly increase until scrape
        # time falls between the desired `scrape_duration`.
        # Increasing this value too much will result in huge memory consumption if too
        # many metrics are being scraped.
        # Default: 4
        # worker_threads: 4
        # Maximum number of metrics to keep in memory until a report is triggered.
        # Changing this value is not recommended unless instructed by the New Relic support team.
        # max_stored_metrics: 10000
        # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms.
        # Changing this value is not recommended unless instructed by the New Relic support team.
        # min_emitter_harvest_period: 200ms

        targets:
          - description: exporter_for_pihole
            urls: ["$HOST_IP:9617"]
        # targets:
        #   - description: Secure etcd example
        #     urls: ["https://192.168.3.1:2379", "https://192.168.3.2:2379", "https://192.168.3.3:2379"]
        #     tls_config:
        #       ca_file_path: "/etc/etcd/etcd-client-ca.crt"
        #       cert_file_path: "/etc/etcd/etcd-client.crt"
        #       key_file_path: "/etc/etcd/etcd-client.key"

        # Proxy to be used by the emitters when submitting metrics. It should be
        # in the format [scheme]://[domain]:[port].
        # The emitter is the component in charge of sending the scraped metrics.
        # This proxy won't be used when scraping metrics from the targets.
        # By default it's empty, meaning that no proxy will be used.
        # emitter_proxy: "http://localhost:8888"

        # Certificate to add to the root CA that the emitter will use when
        # verifying server certificates.
        # If left empty, TLS uses the host's root CA set.
        # emitter_ca_file: "/path/to/cert/server.pem"

        # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account
        # having limited privileges. Defaults to false.
        # disable_autodiscovery: false

        # Whether the emitter should skip TLS verification when submitting data.
        # Defaults to false.
        # emitter_insecure_skip_verify: false

        # Histogram support is based on New Relic's guidelines for higher
        # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md.
        # To better support visualization of this data, percentiles are calculated
        # based on the histogram metrics and sent to New Relic.
        # By default, the following percentiles are calculated: 50, 95 and 99.
        #
        # percentiles:
        #   - 50
        #   - 95
        #   - 99

        transformations:
          - description: "General processing rules"
            rename_attributes:
              - metric_prefix: "pihole_"
                attributes:
                  hostname: "piHoleName"
            ignore_metrics:
              #       # Ignore all the metrics except the ones listed below.
              #       # This is a list that complements the data retrieved by the New
              #       # Relic Kubernetes Integration, that's why Pods and containers are
              #       # not included, because they are already collected by the
              #       # Kubernetes Integration.
              - except:
                  # - pihole_querytypes
                  # - pihole_top_queries
                  # - pihole_reply
                  # - pihole_forward_destinations
                  # - pihole_top_sources
                  - pihole_queries_forwarded
                  - pihole_queries_cached
                  - pihole_unique_clients
                  - pihole_unique_domains
                  - pihole_dns_queries_all_types
                  - pihole_clients_ever_seen
                  - pihole_ads_blocked_today
                  - pihole_status
                  - pihole_domains_being_blocked
                  - pihole_dns_queries_today
                  - pihole_ads_percentage_today
        #     copy_attributes:
        #       # Copy all the labels from the timeseries with metric name
        #       # `kube_hpa_labels` into every timeseries with a metric name that
        #       # starts with `kube_hpa_` only if they share the same `namespace`
        #       # and `hpa` labels.
        #       - from_metric: "kube_hpa_labels"
        #         to_metrics: "kube_hpa_"
        #         match_by:
        #           - namespace
        #           - hpa
        #       - from_metric: "kube_daemonset_labels"
        #         to_metrics: "kube_daemonset_"
        #         match_by:
        #           - namespace
        #           - daemonset
        #       - from_metric: "kube_statefulset_labels"
        #         to_metrics: "kube_statefulset_"
        #         match_by:
        #           - namespace
        #           - statefulset
        #       - from_metric: "kube_endpoint_labels"
        #         to_metrics: "kube_endpoint_"
        #         match_by:
        #           - namespace
        #           - endpoint
        #       - from_metric: "kube_service_labels"
        #         to_metrics: "kube_service_"
        #         match_by:
        #           - namespace
        #           - service
        #       - from_metric: "kube_node_labels"
        #         to_metrics: "kube_node_"
        #         match_by:
        #           - namespace
        #           - node

        # integration definition files required to map metrics to entities
        # definition_files_path: /etc/newrelic-infra/definition-files
        EOT

        ####################################################################################################################################################
        # Run container
        ####################################################################################################################################################
        if [ $(echo {{.NEW_RELIC_REGION}} | grep -i staging | wc -l) -gt 0 ]; then
          REMOTE_WRITE_ENDPOINT=https://staging-metric-api.newrelic.com
        else
          REMOTE_WRITE_ENDPOINT=https://metric-api.newrelic.com
        fi

        docker pull newrelic/nri-prometheus:2.5
        docker run -d --rm \
        -v /etc/nri-prometheus/nri-prometheus-config.yml:/etc/nri-prometheus/config.yml \
        -e LICENSE_KEY={{.NEW_RELIC_LICENSE_KEY}} \
        -e METRIC_API_URL=$REMOTE_WRITE_ENDPOINT/metric/v1/infra \
        -p 9091:8080 \
        --name nri-prometheus newrelic/nri-prometheus:2.5

        docker ps -a

        ####################################################################################################################################################
        # Cleanup
        ####################################################################################################################################################
        if [ -f /tmp/newrelic/nri-prometheus-config_old.yml ]; then
          mv /tmp/newrelic/nri-prometheus-config_old.yml /etc/nri-prometheus/
        fi

    # restart:
    #   cmds:
    #     - |
    #       if [ {{.IS_SYSTEMCTL}} -gt 0 ]; then
    #         sudo systemctl restart newrelic-infra
    #       else
    #         if [ {{.IS_INITCTL}} -gt 0 ]; then
    #           sudo initctl restart newrelic-infra
    #         else
    #           sudo /etc/init.d/newrelic-infra restart
    #         fi
    #       fi
    #   vars:
    #     IS_SYSTEMCTL:
    #       sh: which systemctl | wc -l
    #     IS_INITCTL:
    #       sh: which initctl | wc -l
    # assert_agent_started:
    #   cmds:
    #     - |
    #       # Ensure agent has enough time to start
    #       sleep 10
    #       IS_INFRA_INSTALLED=$(sudo ps aux | grep newrelic-infra-service | grep -v grep | wc -l)
    #       if [ $IS_INFRA_INSTALLED -eq 0 ] ; then
    #         echo "The infrastructure agent has not started after installing. Please try again later, or see our documentation for installing manually https://docs.newrelic.com/docs/using-new-relic/cross-product-functions/install-configure/install-new-relic" >> /dev/stderr
    #         exit 31
    #       fi
    cleanup:
      - |
        sudo rm -rf /tmp/newrelic

postInstall:
  info: |2
      ⚙️  The Prometheus configuration file can be found in /opt/prometheus/prometheus.yml
      ⚙️  The nri-prometheus configuration file can be found in /etc/nri-prometheus/nri-prometheus-config.yml
      
      prometheus and pihole_exporter are now running as a background services and
      will launch at login (via systemd).

      To stop, run:
      > systemctl disable pihole_exporter
      > systemctl disable prometheus

      nri-prometheus is now running. To stop, run:
      > docker stop nri-prometheus
